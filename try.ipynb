{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cifar10                          \n",
    "from PIL import Image\n",
    "\n",
    "def main(argv=None):\n",
    "    \n",
    "  with tf.Graph().as_default() as g:  \n",
    "    \n",
    "    # Please change this file name\n",
    "    # (このファイル名は変更してください。)\n",
    "    img = Image.open('test.jpg').convert(\"RGB\")\n",
    "    \n",
    "    # Resize\n",
    "    img = img.resize((32,32), Image.LANCZOS)\n",
    "    \n",
    "    # raw\n",
    "    raw = img.getdata()\n",
    "    \n",
    "    # One dimensional array \n",
    "    arr = np.array(raw)\n",
    "    raw = arr.flatten()\n",
    "    \n",
    "    # R <-> B\n",
    "    for i in range(32*32):\n",
    "      w = raw[(i*3)]  \n",
    "      raw[(i*3)] = raw[(i*3)+2]\n",
    "      raw[(i*3)+2] = w\n",
    "    image = tf.reshape(raw, [32,32,3])    \n",
    "        \n",
    "    # Crop the central [height, width] of the image.    \n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(image, 24, 24)\n",
    "    \n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(resized_image)  \n",
    "    \n",
    "    # Shaping\n",
    "    images = tf.reshape(float_image,[1,24,24,3])\n",
    "\n",
    "    # Inference .\n",
    "    logits = cifar10.inference(images)\n",
    "    \n",
    "    # Softmax\n",
    "    out = tf.nn.softmax(logits)\n",
    "\n",
    "    # Restore\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        cifar10.MOVING_AVERAGE_DECAY)\n",
    "    variables_to_restore = variable_averages.variables_to_restore()\n",
    "    saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "      ckpt = tf.train.get_checkpoint_state('train')\n",
    "      if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "        # Run\n",
    "        result = sess.run([out])\n",
    "        result = np.array(result)\n",
    "        softmax = result.flatten()\n",
    "        \n",
    "        # Output\n",
    "        print(\"Output:\", np.round(softmax, 2))         \n",
    "      else:\n",
    "        print('No checkpoint file found')  \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
